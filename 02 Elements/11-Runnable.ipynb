{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89089530",
   "metadata": {},
   "source": [
    "# Runnable in LangGraph: The Executable Interface\n",
    "\n",
    "A Runnable in LangGraph is the compiled, executable form of a StateGraph. It's the interface that allows you to invoke, stream, and interact with your graph after it has been compiled. Runnables provide the actual execution capabilities for your LangGraph applications.\n",
    "\n",
    "## Key Features:\n",
    "- **Execution Interface**: Provides methods to run your compiled graph\n",
    "- **State Management**: Handles state flow during execution\n",
    "- **Multiple Execution Modes**: Support for sync, async, and streaming execution\n",
    "- **Error Handling**: Built-in error management during execution\n",
    "\n",
    "## Creating a Runnable:\n",
    "\n",
    "### **Basic Runnable Creation**\n",
    "```python\n",
    "from langgraph import StateGraph\n",
    "from typing import TypedDict\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    user_input: str\n",
    "    result: str\n",
    "\n",
    "# Create and compile graph\n",
    "graph = StateGraph(MyState)\n",
    "graph.add_node(\"process\", process_input)\n",
    "graph.add_edge(\"process\", \"generate\")\n",
    "graph.set_entry_point(\"process\")\n",
    "\n",
    "# Compile into Runnable\n",
    "runnable = graph.compile()\n",
    "```\n",
    "\n",
    "### **Runnable with Configuration**\n",
    "```python\n",
    "# Compile with custom configuration\n",
    "runnable = graph.compile(\n",
    "    debug=True,\n",
    "    checkpointer=None,\n",
    "    interrupt_before=None,\n",
    "    interrupt_after=None\n",
    ")\n",
    "```\n",
    "\n",
    "## Execution Methods:\n",
    "\n",
    "### **Synchronous Execution**\n",
    "```python\n",
    "# Basic invocation\n",
    "result = runnable.invoke({\n",
    "    \"user_input\": \"Hello World\",\n",
    "    \"result\": \"\"\n",
    "})\n",
    "\n",
    "print(result[\"result\"])  # Output: Processed: HELLO WORLD\n",
    "```\n",
    "\n",
    "### **Asynchronous Execution**\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def run_async():\n",
    "    result = await runnable.ainvoke({\n",
    "        \"user_input\": \"Hello World\",\n",
    "        \"result\": \"\"\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# Execute asynchronously\n",
    "result = asyncio.run(run_async())\n",
    "```\n",
    "\n",
    "### **Streaming Execution**\n",
    "```python\n",
    "# Stream intermediate results\n",
    "for chunk in runnable.stream({\n",
    "    \"user_input\": \"Hello World\",\n",
    "    \"result\": \"\"\n",
    "}):\n",
    "    print(f\"Step: {chunk}\")\n",
    "    # Output:\n",
    "    # Step: {'process': {'processed_data': 'HELLO WORLD'}}\n",
    "    # Step: {'generate': {'result': 'Processed: HELLO WORLD'}}\n",
    "```\n",
    "\n",
    "### **Batch Execution**\n",
    "```python\n",
    "# Process multiple inputs\n",
    "inputs = [\n",
    "    {\"user_input\": \"Hello\", \"result\": \"\"},\n",
    "    {\"user_input\": \"World\", \"result\": \"\"},\n",
    "    {\"user_input\": \"LangGraph\", \"result\": \"\"}\n",
    "]\n",
    "\n",
    "results = runnable.batch(inputs)\n",
    "for result in results:\n",
    "    print(result[\"result\"])\n",
    "```\n",
    "\n",
    "## Advanced Execution Patterns:\n",
    "\n",
    "### **Streaming with Configuration**\n",
    "```python\n",
    "# Stream with specific configuration\n",
    "for chunk in runnable.stream(\n",
    "    {\"user_input\": \"Hello World\", \"result\": \"\"},\n",
    "    config={\"recursion_limit\": 50}\n",
    "):\n",
    "    print(f\"Chunk: {chunk}\")\n",
    "```\n",
    "\n",
    "### **Async Streaming**\n",
    "```python\n",
    "async def stream_async():\n",
    "    async for chunk in runnable.astream({\n",
    "        \"user_input\": \"Hello World\",\n",
    "        \"result\": \"\"\n",
    "    }):\n",
    "        print(f\"Async chunk: {chunk}\")\n",
    "\n",
    "# Run async streaming\n",
    "asyncio.run(stream_async())\n",
    "```\n",
    "\n",
    "### **Execution with Callbacks**\n",
    "```python\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "\n",
    "class MyCallbackHandler(BaseCallbackHandler):\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        print(f\"Starting execution with inputs: {inputs}\")\n",
    "    \n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        print(f\"Execution completed with outputs: {outputs}\")\n",
    "\n",
    "# Execute with callbacks\n",
    "result = runnable.invoke(\n",
    "    {\"user_input\": \"Hello World\", \"result\": \"\"},\n",
    "    config={\"callbacks\": [MyCallbackHandler()]}\n",
    ")\n",
    "```\n",
    "\n",
    "## Runnable State Management:\n",
    "\n",
    "### **State Inspection**\n",
    "```python\n",
    "# Get current state during execution\n",
    "def inspect_state(state):\n",
    "    print(f\"Current state: {state}\")\n",
    "    return state\n",
    "\n",
    "# Add inspection node\n",
    "graph.add_node(\"inspect\", inspect_state)\n",
    "```\n",
    "\n",
    "### **State Persistence**\n",
    "```python\n",
    "# Create runnable with state persistence\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "runnable = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Execute with thread ID for state persistence\n",
    "result = runnable.invoke(\n",
    "    {\"user_input\": \"Hello World\", \"result\": \"\"},\n",
    "    config={\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    ")\n",
    "```\n",
    "\n",
    "### **State Updates**\n",
    "```python\n",
    "# Update state during execution\n",
    "def update_state(state):\n",
    "    return {\n",
    "        \"step_count\": state.get(\"step_count\", 0) + 1,\n",
    "        \"last_updated\": datetime.now().isoformat()\n",
    "    }\n",
    "```\n",
    "\n",
    "## Error Handling:\n",
    "\n",
    "### **Execution Error Handling**\n",
    "```python\n",
    "try:\n",
    "    result = runnable.invoke({\n",
    "        \"user_input\": \"Hello World\",\n",
    "        \"result\": \"\"\n",
    "    })\n",
    "    print(\"Execution successful:\", result)\n",
    "except Exception as e:\n",
    "    print(f\"Execution failed: {e}\")\n",
    "```\n",
    "\n",
    "### **Streaming Error Handling**\n",
    "```python\n",
    "try:\n",
    "    for chunk in runnable.stream({\n",
    "        \"user_input\": \"Hello World\",\n",
    "        \"result\": \"\"\n",
    "    }):\n",
    "        print(f\"Chunk: {chunk}\")\n",
    "except Exception as e:\n",
    "    print(f\"Streaming failed: {e}\")\n",
    "```\n",
    "\n",
    "### **Async Error Handling**\n",
    "```python\n",
    "async def safe_execution():\n",
    "    try:\n",
    "        result = await runnable.ainvoke({\n",
    "            \"user_input\": \"Hello World\",\n",
    "            \"result\": \"\"\n",
    "        })\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Async execution failed: {e}\")\n",
    "        return None\n",
    "```\n",
    "\n",
    "## Runnable Configuration:\n",
    "\n",
    "### **Execution Configuration**\n",
    "```python\n",
    "# Configure execution parameters\n",
    "config = {\n",
    "    \"recursion_limit\": 100,\n",
    "    \"max_concurrency\": 10,\n",
    "    \"timeout\": 30,\n",
    "    \"callbacks\": [MyCallbackHandler()]\n",
    "}\n",
    "\n",
    "result = runnable.invoke(\n",
    "    {\"user_input\": \"Hello World\", \"result\": \"\"},\n",
    "    config=config\n",
    ")\n",
    "```\n",
    "\n",
    "### **Thread Configuration**\n",
    "```python\n",
    "# Execute with thread-specific configuration\n",
    "result = runnable.invoke(\n",
    "    {\"user_input\": \"Hello World\", \"result\": \"\"},\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"user-123\",\n",
    "            \"checkpoint_id\": \"checkpoint-456\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "## Runnable Methods:\n",
    "\n",
    "### **Invoke Methods**\n",
    "```python\n",
    "# Synchronous invoke\n",
    "result = runnable.invoke(input_data)\n",
    "\n",
    "# Asynchronous invoke\n",
    "result = await runnable.ainvoke(input_data)\n",
    "\n",
    "# Batch invoke\n",
    "results = runnable.batch([input1, input2, input3])\n",
    "```\n",
    "\n",
    "### **Stream Methods**\n",
    "```python\n",
    "# Synchronous stream\n",
    "for chunk in runnable.stream(input_data):\n",
    "    process_chunk(chunk)\n",
    "\n",
    "# Asynchronous stream\n",
    "async for chunk in runnable.astream(input_data):\n",
    "    await process_chunk_async(chunk)\n",
    "```\n",
    "\n",
    "### **Batch Methods**\n",
    "```python\n",
    "# Batch processing\n",
    "results = runnable.batch(inputs)\n",
    "\n",
    "# Async batch processing\n",
    "results = await runnable.abatch(inputs)\n",
    "```\n",
    "\n",
    "## Runnable Properties:\n",
    "\n",
    "### **Graph Information**\n",
    "```python\n",
    "# Get graph structure\n",
    "print(\"Nodes:\", runnable.nodes)\n",
    "print(\"Edges:\", runnable.edges)\n",
    "print(\"Entry point:\", runnable.entry_point)\n",
    "```\n",
    "\n",
    "### **Execution Metadata**\n",
    "```python\n",
    "# Get execution information\n",
    "print(\"Graph name:\", runnable.name)\n",
    "print(\"Graph description:\", runnable.description)\n",
    "print(\"Graph version:\", runnable.version)\n",
    "```\n",
    "\n",
    "## Best Practices:\n",
    "\n",
    "### **1. Execution Management**\n",
    "- Use appropriate execution method for your use case\n",
    "- Handle errors gracefully at execution level\n",
    "- Monitor execution performance\n",
    "- Use streaming for long-running processes\n",
    "\n",
    "### **2. State Management**\n",
    "- Design state structure for your execution needs\n",
    "- Use state persistence for multi-step processes\n",
    "- Validate state before execution\n",
    "- Handle state transitions properly\n",
    "\n",
    "### **3. Error Handling**\n",
    "- Always wrap execution in try-catch blocks\n",
    "- Provide meaningful error messages\n",
    "- Implement fallback mechanisms\n",
    "- Log execution errors\n",
    "\n",
    "### **4. Performance**\n",
    "- Use async execution for I/O operations\n",
    "- Implement proper timeout handling\n",
    "- Monitor memory usage during execution\n",
    "- Use batch processing for multiple inputs\n",
    "\n",
    "## Common Use Cases:\n",
    "\n",
    "### **API Endpoints**\n",
    "```python\n",
    "# Use runnable in API endpoint\n",
    "@app.post(\"/process\")\n",
    "async def process_input(request: Request):\n",
    "    result = await runnable.ainvoke({\n",
    "        \"user_input\": request.json[\"input\"],\n",
    "        \"result\": \"\"\n",
    "    })\n",
    "    return {\"result\": result[\"result\"]}\n",
    "```\n",
    "\n",
    "### **Background Tasks**\n",
    "```python\n",
    "# Use runnable in background task\n",
    "async def background_processing():\n",
    "    result = await runnable.ainvoke({\n",
    "        \"user_input\": \"Background task\",\n",
    "        \"result\": \"\"\n",
    "    })\n",
    "    return result\n",
    "```\n",
    "\n",
    "### **Interactive Applications**\n",
    "```python\n",
    "# Use runnable in interactive app\n",
    "def interactive_chat():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        result = runnable.invoke({\n",
    "            \"user_input\": user_input,\n",
    "            \"result\": \"\"\n",
    "        })\n",
    "        print(f\"Bot: {result['result']}\")\n",
    "```\n",
    "\n",
    "## Benefits:\n",
    "- **Flexible Execution**: Multiple execution modes\n",
    "- **State Management**: Built-in state handling\n",
    "- **Error Handling**: Robust error management\n",
    "- **Performance**: Optimized execution\n",
    "- **Integration**: Easy integration with other systems\n",
    "\n",
    "## Tips for Success:\n",
    "- Choose the right execution method for your needs\n",
    "- Handle errors at the execution level\n",
    "- Use streaming for long-running processes\n",
    "- Implement proper state management\n",
    "- Monitor execution performance\n",
    "- Test with various input scenarios\n",
    "- Use async execution for I/O operations\n",
    "- Implement proper timeout handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc119f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
